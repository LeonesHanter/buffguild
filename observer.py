# -*- coding: utf-8 -*-
import logging
import time
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

import aiohttp

from .constants import CLASS_ABILITIES, RACE_NAMES
from .models import Job
from .scheduler import Scheduler
from .health import TokenHealthMonitor
from .validators import InputValidator
from .utils import timestamp_to_moscow, now_moscow, format_moscow_time, normalize_text
from .job_storage import JobStorage  # –ù–û–í–û–ï

logger = logging.getLogger(__name__)


@dataclass
class ActiveJobInfo:
    job: Job
    letters: str
    cmid: Optional[int]
    message_id: int
    registration_time: float


@dataclass
class BuffResultInfo:
    tokens_info: List[Dict[str, Any]]
    total_value: int
    expected_count: int
    completed_count: int


class ObserverBot:
    def __init__(self, tm, executor):
        self.tm = tm
        self.executor = executor

        # Scheduler —Å –∫–æ–ª–±—ç–∫–æ–º –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
        self.scheduler = Scheduler(tm, executor, on_buff_complete=self._handle_buff_completion)
        self.health_monitor = TokenHealthMonitor(tm)

        self.observer = tm.get_observer()
        if not self.observer.access_token:
            raise RuntimeError("Observer token has empty access_token")
        if not self.observer.source_peer_id:
            raise RuntimeError("Observer source_chat_id is missing")

        self.poll_interval = float(tm.settings.get("poll_interval", 2.0))
        self.poll_count = int(tm.settings.get("poll_count", 20))

        # –•—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –±–∞—Ñ–æ–≤
        self._active_jobs: Dict[int, ActiveJobInfo] = {}
        self._buff_results: Dict[int, BuffResultInfo] = {}

        logging.info("ü§ñ MultiTokenBot STARTED (Observer=LongPoll)")
        logging.info(f"üìã Tokens: {len(tm.tokens)}")
        logging.info(f"üõ∞Ô∏è Target poll: interval={self.poll_interval}s, count={self.poll_count}")

        self._lp_server: str = ""
        self._lp_key: str = ""
        self._lp_ts: str = ""

    def _parse_baf_letters(self, text: str) -> str:
        text_n = normalize_text(text)
        if not text_n.startswith("!–±–∞—Ñ"):
            return ""
        s = text_n[4:].strip()
        if not s:
            return ""
        s = s[:4]
        allowed = set()
        for cls in CLASS_ABILITIES.values():
            allowed.update(cls["abilities"].keys())
        out = "".join([ch for ch in s if ch in allowed])
        return out[:4]

    def _is_apo_cmd(self, text: str) -> bool:
        return normalize_text(text).startswith("!–∞–ø–æ")

    def _is_baf_cancel_cmd(self, text: str) -> bool:
        return normalize_text(text) == "!–±–∞—Ñ –æ—Ç–º–µ–Ω–∞"

    def _parse_golosa_cmd(self, text: str) -> Optional[Tuple[str, int]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–º–∞–Ω–¥—ã !–≥–æ–ª–æ—Å–∞"""
        t = (text or "").strip()
        if not normalize_text(t).startswith("!–≥–æ–ª–æ—Å–∞"):
            return None
        parts = t.split()
        if len(parts) != 3:
            return None
        name = parts[1].strip()
        try:
            n = int(parts[2].strip())
        except Exception:
            return None
        if not name:
            return None
        return name, max(0, n)

    def _apply_manual_voices_by_name(self, name: str, n: int) -> str:
        """–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ä—É—á–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤"""
        token = self.tm.get_token_by_name(name)
        if not token:
            return f"‚ùå –¢–æ–∫–µ–Ω —Å –∏–º–µ–Ω–µ–º '{name}' –Ω–µ –Ω–∞–π–¥–µ–Ω."
        token.update_voices_manual(n)
        # —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã–π –º–µ—Ö–∞–Ω–∏–∑–º
        return f"‚úÖ {token.name}: –≥–æ–ª–æ—Å–∞ –≤—ã—Å—Ç–∞–≤–ª–µ–Ω—ã = {n}"

    def _format_races_simple(self, token) -> str:
        # force cleanup —á—Ç–æ–±—ã !–∞–ø–æ –ø–æ–∫–∞–∑—ã–≤–∞–ª–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
        token._cleanup_expired_temp_races(force=True)
        parts = []
        if token.races:
            parts.append("/".join(sorted(token.races)))

        temp_parts = []
        for tr in token.temp_races:
            race_key = tr["race"]
            expires = tr["expires"]
            remaining = int(expires - time.time())
            if remaining > 0:
                if remaining >= 3600:
                    hours = remaining // 3600
                    minutes = (remaining % 3600) // 60
                    time_str = f"{hours}—á{minutes:02d}–º"
                else:
                    minutes = remaining // 60
                    seconds = remaining % 60
                    time_str = f"{minutes}–º{seconds:02d}—Å"
                temp_parts.append(f"{race_key}({time_str})")

        if temp_parts:
            parts.append("/".join(sorted(temp_parts)))

        return "/".join(parts) if parts else "-"

    def _format_apo_status(self) -> str:
        apostles = [t for t in self.tm.all_buffers() if t.class_type == "apostle"]
        warlocks = [t for t in self.tm.all_buffers() if t.class_type == "warlock"]
        paladins = [
            t
            for t in self.tm.all_buffers()
            if t.class_type in ("crusader", "light_incarnation")
        ]

        lines: List[str] = []

        if apostles:
            lines.append("üé≠ –ê–ø–æ—Å—Ç–æ–ª—ã")
            for t in apostles:
                races_str = self._format_races_simple(t)
                manual = " ‚ö†Ô∏è" if t.needs_manual_voices else ""
                lines.append(f" {t.name}: {races_str} | üó£Ô∏è {t.voices}{manual}")
            lines.append("")

        if warlocks:
            lines.append("üßô –ü—Ä–æ–∫–ª–∏–Ω–∞—é—â–∏–µ")
            for t in warlocks:
                manual = " ‚ö†Ô∏è" if t.needs_manual_voices else ""
                lines.append(f" {t.name} | üó£Ô∏è {t.voices}{manual}")
            lines.append("")

        if paladins:
            lines.append("‚öîÔ∏è –ü–∞–ª–∞–¥–∏–Ω—ã")
            for t in paladins:
                manual = " ‚ö†Ô∏è" if t.needs_manual_voices else ""
                lines.append(f" {t.name} (lvl {t.level}) | üó£Ô∏è {t.voices}{manual}")
            lines.append("")

        if not lines:
            return "–ù–µ—Ç –±–∞—Ñ–µ—Ä–æ–≤ –≤ –∫–æ–Ω—Ñ–∏–≥–µ."

        return "\n".join(lines).strip()

    def _parse_doprasa_cmd(
        self, text: str, msg_item: Dict[str, Any]
    ) -> Optional[Tuple[str, Optional[str], Optional[int], str]]:
        t = InputValidator.sanitize_text(text, max_length=50)
        if not normalize_text(t).startswith("/–¥–æ–ø—Ä–∞—Å–∞"):
            return None

        parts = t.split()
        if len(parts) < 2 or len(parts) > 3:
            return None

        race = parts[1].strip().lower()
        if not InputValidator.validate_race_key(race):
            return None

        token_name = None
        if len(parts) == 3:
            token_name = parts[2].strip()
            if not InputValidator.validate_token_name(token_name):
                return None

        original_timestamp = None
        if "reply_message" in msg_item:
            original_timestamp = InputValidator.validate_timestamp(
                msg_item["reply_message"].get("date")
            )
        elif "fwd_messages" in msg_item and msg_item["fwd_messages"]:
            original_timestamp = InputValidator.validate_timestamp(
                msg_item["fwd_messages"][0].get("date")
            )

        return race, token_name, original_timestamp, text

    def _handle_doprasa_command(
        self, from_id: int, text: str, msg_item: Dict[str, Any]
    ) -> None:
        parsed = self._parse_doprasa_cmd(text, msg_item)
        if not parsed:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                "‚ùå –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /–¥–æ–ø—Ä–∞—Å–∞ [—Ä–∞—Å–∞] [–∏–º—è_—Ç–æ–∫–µ–Ω–∞_–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ]\n"
                "üìå –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ä–∞—Å—ã, –µ—Å–ª–∏ –∞–ø–æ—Å—Ç–æ–ª –£–ñ–ï –ø–æ–ª—É—á–∏–ª –±–∞—Ñ –≤ –¥—Ä—É–≥–æ–º –º–µ—Å—Ç–µ\n"
                "üìå –ù—É–∂–Ω–æ –ø–µ—Ä–µ—Å–ª–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —É—Å–ø–µ—à–Ω—ã–º –±–∞—Ñ–æ–º\n"
                "–ü—Ä–∏–º–µ—Ä—ã:\n"
                " /–¥–æ–ø—Ä–∞—Å–∞ —á\n"
                " /–¥–æ–ø—Ä–∞—Å–∞ —á –ê–ø–æ—Å—Ç–æ–ª2",
                None,
            )
            return

        race_key, token_name, original_timestamp, _ = parsed

        token = None
        if token_name:
            token = self.tm.get_token_by_name(token_name)
            if not token:
                self.observer.send_to_peer(
                    self.observer.source_peer_id,
                    f"‚ùå –¢–æ–∫–µ–Ω '{token_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω.",
                    None,
                )
                return

            if token.owner_vk_id == 0:
                token.fetch_owner_id_lazy()
            if token.owner_vk_id != 0 and token.owner_vk_id != from_id:
                self.observer.send_to_peer(
                    self.observer.source_peer_id,
                    f"‚ùå –ù–µ—Ç –ø—Ä–∞–≤ –Ω–∞ '{token_name}'.",
                    None,
                )
                return
        else:
            token = self.tm.get_token_by_sender_id(from_id)
            if not token:
                self.observer.send_to_peer(
                    self.observer.source_peer_id,
                    f"‚ùå –ê–ø–æ—Å—Ç–æ–ª —Å –≤–∞—à–∏–º ID ({from_id}) –Ω–µ –Ω–∞–π–¥–µ–Ω.",
                    None,
                )
                return

        # –∑–∞—â–∏—Ç–∞: —Ç–æ–∫–µ–Ω –Ω–∞–±–ª—é–¥–∞—Ç–µ–ª—è –Ω–µ –º–æ–∂–µ—Ç –ø–æ–ª—É—á–∞—Ç—å —Ä–∞—Å—ã
        if token.id == self.observer.id:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                "‚ùå Observer —Ç–æ–∫–µ–Ω –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∞–ø–æ—Å—Ç–æ–ª–æ–º –∏ –Ω–µ –º–æ–∂–µ—Ç –ø–æ–ª—É—á–∞—Ç—å —Ä–∞—Å—ã.",
                None,
            )
            return

        if token.class_type != "apostle":
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                f"‚ùå {token.name} –Ω–µ –∞–ø–æ—Å—Ç–æ–ª.",
                None,
            )
            return

        token._cleanup_expired_temp_races(force=True)

        if race_key in token.races:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                f"‚ö†Ô∏è –£ {token.name} —É–∂–µ –µ—Å—Ç—å –ø–æ—Å—Ç–æ—è–Ω–Ω–∞—è —Ä–∞—Å–∞.",
                None,
            )
            return

        if any(tr["race"] == race_key for tr in token.temp_races):
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                f"‚ö†Ô∏è –£ {token.name} —É–∂–µ –µ—Å—Ç—å —ç—Ç–∞ –≤—Ä–µ–º–µ–Ω–Ω–∞—è —Ä–∞—Å–∞.",
                None,
            )
            return

        if token.get_temp_race_count() >= 1:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                f"‚ö†Ô∏è –£ {token.name} —É–∂–µ –µ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–∞—è —Ä–∞—Å–∞ (–º–æ–∂–Ω–æ —Ç–æ–ª—å–∫–æ –æ–¥–Ω—É).",
                None,
            )
            return

        if not original_timestamp:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                "‚ùå –ù—É–∂–Ω–æ –ø–µ—Ä–µ—Å–ª–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —É—Å–ø–µ—à–Ω—ã–º –±–∞—Ñ–æ–º.\n"
                "üìå –û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –±–∞—Ñ–æ–º –∏–ª–∏ –ø–µ—Ä–µ—à–ª–∏—Ç–µ –µ–≥–æ.",
                None,
            )
            return

        start_moscow = timestamp_to_moscow(original_timestamp)
        end_moscow = timestamp_to_moscow(original_timestamp + 2 * 3600)

        if end_moscow < now_moscow():
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                f"‚ùå –í—Ä–µ–º—è –±–∞—Ñ–∞ —É–∂–µ –∏—Å—Ç–µ–∫–ª–æ (—Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {format_moscow_time(start_moscow)}).",
                None,
            )
            return

        success = token.add_temporary_race(
            race_key, expires_at=original_timestamp + 2 * 3600
        )

        if success:
            self.tm.update_race_index(token)
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                f"‚úÖ {token.name}: –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–∞—è —Ä–∞—Å–∞ '{RACE_NAMES.get(race_key, race_key)}'\n"
                f"‚è∞ {format_moscow_time(start_moscow)} ‚Üí {format_moscow_time(end_moscow)}\n"
                f"üìå –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å !–±–∞—Ñ{race_key}",
                None,
            )
        else:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ä–∞—Å—É –¥–ª—è {token.name}.",
                None,
            )

    def _handle_health_command(self, from_id: int, text: str) -> None:
        report = self.health_monitor.get_detailed_report()
        if len(report) > 4000:
            report = report[:4000] + "\n... (—Å–æ–æ–±—â–µ–Ω–∏–µ –æ–±—Ä–µ–∑–∞–Ω–æ)"
        self.observer.send_to_peer(self.observer.source_peer_id, report, None)

    def _handle_diagnostic_command(self, from_id: int, text: str) -> None:
        parts = text.split()
        if len(parts) == 1:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                "‚ùå –£–∫–∞–∂–∏—Ç–µ –∏–º—è —Ç–æ–∫–µ–Ω–∞: !–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ [–∏–º—è_—Ç–æ–∫–µ–Ω–∞]",
                None,
            )
            return

        token_name = parts[1].strip()
        report = self.health_monitor.get_detailed_report(token_name)
        self.observer.send_to_peer(self.observer.source_peer_id, report, None)

    def _lp_get_server(self) -> bool:
        data = {
            "access_token": self.observer.access_token,
            "v": "5.131",
            "lp_version": 3,
        }
        ret = self.observer._vk.call(
            self.observer._vk.post("messages.getLongPollServer", data)
        )
        if "error" in ret:
            err = ret["error"]
            logging.error(
                f"‚ùå LongPollServer error {err.get('error_code')} {err.get('error_msg')}"
            )
            return False

        resp = ret.get("response", {})
        self._lp_server = str(resp.get("server", "")).strip()
        self._lp_key = str(resp.get("key", "")).strip()
        self._lp_ts = str(resp.get("ts", "")).strip()
        if not self._lp_server or not self._lp_key or not self._lp_ts:
            logging.error("‚ùå LongPollServer: missing server/key/ts")
            return False

        logging.info(f"‚úÖ LongPoll initialized: server={self._lp_server}, ts={self._lp_ts}")
        return True

    def _lp_check(self) -> Optional[Dict[str, Any]]:
        server = "https://" + self._lp_server
        data = {
            "act": "a_check",
            "key": self._lp_key,
            "ts": self._lp_ts,
            "wait": 25,
            "mode": 2,
            "version": 3,
        }
        try:
            return self.observer._vk.call(self.observer._vk.raw_post(server, data))
        except aiohttp.ClientError as e:
            logging.error(f"üì° –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ LongPoll: {e}")
            return None
        except Exception as e:
            logging.error(f"‚ùå LongPoll a_check exception: {e}", exc_info=True)
            return None

    def _send_registration_notification(self, from_id: int, letters: str, cmid: int) -> int:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –±–∞—Ñ–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç message_id (–∏–ª–∏ 0)."""
        notification_text = (
            f"‚úÖ –ë–∞—Ñ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω: {letters}\n"
            f"üìä –û–∂–∏–¥–∞–µ—Ç—Å—è –±–∞—Ñ–æ–≤: {len(letters)}\n"
            f"üìå –î–ª—è –æ—Ç–º–µ–Ω—ã –Ω–∞–ø–∏—à–∏—Ç–µ: !–±–∞—Ñ –æ—Ç–º–µ–Ω–∞"
        )
        sent_ok, send_status = self.observer.send_to_peer(
            self.observer.source_peer_id, notification_text
        )
        if sent_ok and "OK:" in send_status:
            try:
                message_id = int(send_status.split(":")[1])
                return message_id
            except Exception:
                pass
        return 0

    def _send_final_notification(self, user_id: int) -> None:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –±–∞—Ñ–µ, –∫–æ–≥–¥–∞ –≤—Å–µ –±–∞—Ñ—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã."""
        user_data = self._buff_results.get(user_id)
        if not user_data or not user_data.tokens_info:
            return

        tokens_text = []
        for token_info in user_data.tokens_info:
            token_text = f"{token_info['token_name']}({token_info['buff_value']}"
            if token_info["is_critical"]:
                token_text += "üçÄ"
            token_text += ")"
            tokens_text.append(token_text)

        notification_text = (
            "üéâ –ë–∞—Ñ —É—Å–ø–µ—à–Ω–æ –≤—ã–¥–∞–Ω!\n"
            f"üìà –ù–∞—á–∏—Å–ª–µ–Ω–æ: {', '.join(tokens_text)}\n"
            f"üìâ –í—ã—á—Ç–µ–Ω–æ: ({user_data.total_value}) –±–∞–ª–∞–Ω—Å–∞"
        )

        sent_ok, send_status = self.observer.send_to_peer(
            self.observer.source_peer_id, notification_text
        )
        if not sent_ok:
            logging.error(
                f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ {user_id}: {send_status}"
            )
            return

        # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏
        self._buff_results.pop(user_id, None)
        self._active_jobs.pop(user_id, None)

    def _handle_buff_completion(self, job: Job, buff_info: Dict) -> None:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –±–∞—Ñ–∞ - –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ Scheduler."""
        if not job or not buff_info:
            return

        user_id = job.sender_id

        if user_id not in self._active_jobs:
            logging.warning(f"‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω –±–∞—Ñ –¥–ª—è –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
            return

        buff_value = buff_info.get("buff_value", 0)
        is_critical = buff_info.get("is_critical", False)
        buff_name = buff_info.get("buff_name", "")
        token_name = buff_info.get("token_name", "")

        original_buff_value = buff_value
        original_is_critical = is_critical

        if buff_name and ("30%" in buff_name or "+30%" in buff_name):
            is_critical = True
            buff_value = 150
            logging.info(
                f"üéØ Observer: –ü–ï–†–ï–û–ü–†–ï–î–ï–õ–ï–ù–û –∫–∞–∫ –∫—Ä–∏—Ç –ø–æ –ø—Ä–æ—Ü–µ–Ω—Ç—É –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏: {buff_name}"
            )
        elif buff_name and ("20%" in buff_name or "+20%" in buff_name):
            is_critical = False
            buff_value = 100
            logging.info(
                f"üìä Observer: –ü–ï–†–ï–û–ü–†–ï–î–ï–õ–ï–ù–û –∫–∞–∫ –æ–±—ã—á–Ω—ã–π –ø–æ –ø—Ä–æ—Ü–µ–Ω—Ç—É –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏: {buff_name}"
            )

        if (
            original_buff_value != buff_value
            or original_is_critical != is_critical
        ):
            logging.info(
                f"üîÑ Observer: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –±–∞—Ñ–∞ {token_name}: "
                f"{original_buff_value}->{buff_value}, "
                f"–∫—Ä–∏—Ç {original_is_critical}->{is_critical}"
            )

        logging.info(
            f"üì• Observer: –ü–æ–ª—É—á–µ–Ω –±–∞—Ñ –æ—Ç {token_name}: "
            f"–∑–Ω–∞—á–µ–Ω–∏–µ={buff_value}, –∫—Ä–∏—Ç={is_critical}, –Ω–∞–∑–≤–∞–Ω–∏–µ='{buff_name}'"
        )

        if user_id not in self._buff_results:
            letters = self._active_jobs[user_id].letters
            self._buff_results[user_id] = BuffResultInfo(
                tokens_info=[],
                total_value=0,
                expected_count=len(letters),
                completed_count=0,
            )

        user_data = self._buff_results[user_id]
        user_data.tokens_info.append(
            {
                "token_name": token_name,
                "buff_value": buff_value,
                "is_critical": is_critical,
            }
        )
        user_data.total_value += buff_value
        user_data.completed_count += 1

        logging.info(
            f"üìä Observer: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id}: "
            f"–≤—ã–ø–æ–ª–Ω–µ–Ω–æ {user_data.completed_count}/{user_data.expected_count} –±–∞—Ñ–æ–≤"
        )

        if user_data.completed_count >= user_data.expected_count:
            self._send_final_notification(user_id)

    def _handle_baf_cancel_command(self, from_id: int, cmid: int) -> None:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã !–±–∞—Ñ –æ—Ç–º–µ–Ω–∞."""
        job_info = self._active_jobs.get(from_id)
        if not job_info:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                "‚ùå –£ –≤–∞—Å –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –±–∞—Ñ–æ–≤ –¥–ª—è –æ—Ç–º–µ–Ω—ã.",
                None,
            )
            return

        letters = job_info.letters
        cancelled = self.scheduler.cancel_user_jobs(from_id)

        self._buff_results.pop(from_id, None)
        self._active_jobs.pop(from_id, None)

        if cancelled:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                f"‚úÖ –í—Å–µ –≤–∞—à–∏ –±–∞—Ñ—ã ({letters}) –æ—Ç–º–µ–Ω–µ–Ω—ã.",
                None,
            )
        else:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≤–∞—à–∏ –±–∞—Ñ—ã –≤ –æ—á–µ—Ä–µ–¥–∏.",
                None,
            )

    def _handle_new_message(self, msg_item: Dict[str, Any]) -> None:
        text = (msg_item.get("text") or "").strip()
        from_id = int(msg_item.get("from_id", 0))
        peer_id = int(msg_item.get("peer_id", 0))
        cmid = msg_item.get("conversation_message_id")

        if peer_id != self.observer.source_peer_id:
            return
        if from_id <= 0 or not text:
            return

        norm = normalize_text(text)

        if self._is_baf_cancel_cmd(norm):
            self._handle_baf_cancel_command(from_id, cmid)
            return

        if norm in ["!–∑–¥–æ—Ä–æ–≤—å–µ", "!health", "!—Å—Ç–∞—Ç—É—Å"]:
            self._handle_health_command(from_id, text)
            return

        if norm.startswith("!–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞"):
            self._handle_diagnostic_command(from_id, text)
            return

        parsed_g = self._parse_golosa_cmd(text)
        if parsed_g is not None:
            name, n = parsed_g
            token = self.tm.get_token_by_name(name)
            if not token:
                self.observer.send_to_peer(
                    self.observer.source_peer_id,
                    f"‚ùå –¢–æ–∫–µ–Ω —Å –∏–º–µ–Ω–µ–º '{name}' –Ω–µ –Ω–∞–π–¥–µ–Ω.",
                    None,
                )
                return

            if token.owner_vk_id == 0:
                token.fetch_owner_id_lazy()
            if token.owner_vk_id != 0 and token.owner_vk_id != from_id:
                logging.warning(
                    f"‚ö†Ô∏è –ù–µ–∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ !–≥–æ–ª–æ—Å–∞ –æ—Ç {from_id} "
                    f"–¥–ª—è —Ç–æ–∫–µ–Ω–∞ {token.name} (–≤–ª–∞–¥–µ–ª–µ—Ü={token.owner_vk_id})"
                )
                self.observer.send_to_peer(
                    self.observer.source_peer_id,
                    f"‚ùå –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –Ω–∞ —Ç–æ–∫–µ–Ω '{name}'.",
                    None,
                )
                return

            reply = self._apply_manual_voices_by_name(name, n)
            self.observer.send_to_peer(self.observer.source_peer_id, reply, None)
            return

        if norm.startswith("/–¥–æ–ø—Ä–∞—Å–∞"):
            self._handle_doprasa_command(from_id, text, msg_item)
            return

        if self._is_apo_cmd(norm):
            status = self._format_apo_status()
            self.observer.send_to_peer(self.observer.source_peer_id, status, None)
            return

        letters = self._parse_baf_letters(text)
        if letters:
            if from_id in self._active_jobs:
                self.observer.send_to_peer(
                    self.observer.source_peer_id,
                    "‚ùå –£ –≤–∞—Å —É–∂–µ –µ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –±–∞—Ñ—ã. "
                    "–î–æ–∂–¥–∏—Ç–µ—Å—å –∏—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–ª–∏ –æ—Ç–º–µ–Ω–∏—Ç–µ –∫–æ–º–∞–Ω–¥–æ–π '!–±–∞—Ñ –æ—Ç–º–µ–Ω–∞'.",
                    None,
                )
                return

            job = Job(
                sender_id=from_id,
                trigger_text=text,
                letters=letters,
                created_ts=time.time(),
            )
            logging.info(
                f"üéØ !–±–∞—Ñ from {from_id}: {letters} [observer={self.observer.name}]"
            )

            if cmid:
                message_id = self._send_registration_notification(from_id, letters, cmid)
                if message_id > 0:
                    self._active_jobs[from_id] = ActiveJobInfo(
                        job=job,
                        letters=letters,
                        cmid=cmid,
                        message_id=message_id,
                        registration_time=time.time(),
                    )
                    self._buff_results[from_id] = BuffResultInfo(
                        tokens_info=[],
                        total_value=0,
                        expected_count=len(letters),
                        completed_count=0,
                    )

            self.scheduler.enqueue_letters(job, letters)

    def run(self) -> None:
        retry_count = 0
        max_retries = 10
        retry_delay = 5

        while True:
            try:
                if not self._lp_get_server():
                    logging.error(
                        f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å LongPoll —Å–µ—Ä–≤–µ—Ä "
                        f"(–ø–æ–ø—ã—Ç–∫–∞ {retry_count + 1}/{max_retries})"
                    )
                    retry_count += 1
                    if retry_count >= max_retries:
                        logging.critical(
                            "üí• –ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø–æ–ª—É—á–µ–Ω–∏—è LongPoll —Å–µ—Ä–≤–µ—Ä–∞"
                        )
                        break
                    time.sleep(min(retry_delay * retry_count, 300))
                    continue

                retry_count = 0
                logging.info(
                    f"‚úÖ LongPoll –≥–æ—Ç–æ–≤. –°–ª—É—à–∞—é —á–∞—Ç {self.observer.source_peer_id}"
                )

                while True:
                    try:
                        lp = self._lp_check()
                        if not lp:
                            time.sleep(2)
                            continue

                        if "failed" in lp:
                            error_code = lp.get("failed")
                            logging.warning(
                                f"‚ö†Ô∏è LongPoll failed with code: {error_code}"
                            )
                            if error_code == 1:
                                new_ts = lp.get("ts")
                                if new_ts:
                                    self._lp_ts = str(new_ts)
                                    logging.info(
                                        f"üîÑ LongPoll: –æ–±–Ω–æ–≤–ª–µ–Ω ts –Ω–∞ {new_ts}"
                                    )
                                continue
                            elif error_code == 2:
                                logging.info(
                                    "üîÑ LongPoll: –∫–ª—é—á —É—Å—Ç–∞—Ä–µ–ª, –æ–±–Ω–æ–≤–ª—è—é..."
                                )
                                if not self._lp_get_server():
                                    time.sleep(5)
                                continue
                            elif error_code == 3:
                                logging.info(
                                    "üîÑ LongPoll: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —É—Å—Ç–∞—Ä–µ–ª–∞, –æ–±–Ω–æ–≤–ª—è—é..."
                                )
                                if not self._lp_get_server():
                                    time.sleep(5)
                                continue
                            elif error_code == 4:
                                logging.error(
                                    "‚ùå LongPoll: –Ω–µ–≤–µ—Ä–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞"
                                )
                                time.sleep(60)
                                continue
                            else:
                                logging.error(
                                    f"‚ùå LongPoll: –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ {error_code}"
                                )
                                time.sleep(5)
                                continue

                        new_ts = lp.get("ts")
                        if new_ts is not None:
                            self._lp_ts = str(new_ts)

                        updates = lp.get("updates", []) or []
                        if not updates:
                            continue

                        msg_ids: List[int] = []
                        for u in updates:
                            if not isinstance(u, list) or not u:
                                continue
                            if int(u[0]) != 4:
                                continue
                            try:
                                msg_id = int(u[1])
                                p_id = int(u[3])
                            except Exception:
                                continue
                            if p_id == self.observer.source_peer_id:
                                msg_ids.append(msg_id)

                        if not msg_ids:
                            continue

                        items = self.observer.get_by_id(msg_ids)
                        for it in items:
                            self._handle_new_message(it)

                    except aiohttp.ClientError as e:
                        logging.error(f"üì° –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ LongPoll: {e}")
                        time.sleep(5)
                        continue
                    except Exception as e:
                        logging.error(
                            f"‚ùå –û—à–∏–±–∫–∞ –≤ LongPoll —Ü–∏–∫–ª–µ: {e}", exc_info=True
                        )
                        time.sleep(5)
                        continue

            except Exception as e:
                logging.error(
                    f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ Observer: {e}", exc_info=True
                )
                retry_count += 1
                if retry_count >= max_retries:
                    logging.critical(
                        "üí• –ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è"
                    )
                    break

                delay = min(retry_delay * (2**retry_count), 300)
                logging.info(
                    f"üîÑ –ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ {delay} —Å–µ–∫—É–Ω–¥ "
                    f"(–ø–æ–ø—ã—Ç–∫–∞ {retry_count}/{max_retries})"
                )
                time.sleep(delay)
