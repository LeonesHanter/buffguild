# -*- coding: utf-8 -*-
import logging
import time
from typing import Any, Dict, List, Optional, Tuple

import aiohttp

from .constants import CLASS_ABILITIES, RACE_NAMES, RACE_EMOJIS
from .models import Job
from .scheduler import Scheduler
from .health import TokenHealthMonitor
from .utils import timestamp_to_moscow, now_moscow, format_moscow_time, normalize_text
from .commands import (
    parse_baf_letters,
    parse_golosa_cmd,
    parse_doprasa_cmd,
    is_apo_cmd,
    is_baf_cancel_cmd,
)
from .notifications import build_registration_text, build_final_text
from .state_store import JobStateStore


logger = logging.getLogger(__name__)


class ObserverBot:
    def __init__(self, tm, executor):
        self.tm = tm
        self.executor = executor
        self.scheduler = Scheduler(tm, executor, on_buff_complete=self._handle_buff_completion)
        self.health_monitor = TokenHealthMonitor(tm)
        self.observer = self.tm.get_observer()

        if not self.observer.access_token:
            raise RuntimeError("Observer token has empty access_token")
        if not self.observer.source_peer_id:
            raise RuntimeError("Observer source_chat_id is missing")

        self.poll_interval = float(self.tm.settings.get("poll_interval", 2.0))
        self.poll_count = int(self.tm.settings.get("poll_count", 20))

        # Thread-safe state
        self.state = JobStateStore(storage_path="jobs.json")
        self.state.restore_and_enqueue(self.scheduler)

        logging.info("ü§ñ MultiTokenBot STARTED (Observer=LongPoll)")
        logging.info(f"üìã Tokens: {len(self.tm.tokens)}")
        logging.info(
            f"üõ∞Ô∏è Target poll: interval={self.poll_interval}s, count={self.poll_count}"
        )

        self._lp_server: str = ""
        self._lp_key: str = ""
        self._lp_ts: str = ""

        # ... —Ç—É—Ç –ø—Ä–æ–ø—É—â–µ–Ω –∫–æ–¥ _lp_get_server, _lp_check, _restore_active_jobs –∏ —Ç.–ø. ...

    # -------------------- Commands --------------------

    def _handle_health_command(self, from_id: int, text: str) -> None:
        report = self.health_monitor.get_detailed_report()
        if len(report) > 4000:
            report = report[:4000] + "\n... (—Å–æ–æ–±—â–µ–Ω–∏–µ –æ–±—Ä–µ–∑–∞–Ω–æ)"
        self.observer.send_to_peer(self.observer.source_peer_id, report, None)

    def _handle_diagnostic_command(self, from_id: int, text: str) -> None:
        parts = (text or "").split()
        if len(parts) == 1:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                "‚ùå –£–∫–∞–∂–∏—Ç–µ –∏–º—è —Ç–æ–∫–µ–Ω–∞: !–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ [–∏–º—è_—Ç–æ–∫–µ–Ω–∞]",
                None,
            )
            return

        token_name = parts[1].strip()
        report = self.health_monitor.get_detailed_report(token_name)
        self.observer.send_to_peer(self.observer.source_peer_id, report, None)

    def _apply_manual_voices_by_name(self, name: str, n: int) -> str:
        token = self.tm.get_token_by_name(name)
        if not token:
            return f"‚ùå –¢–æ–∫–µ–Ω —Å –∏–º–µ–Ω–µ–º '{name}' –Ω–µ –Ω–∞–π–¥–µ–Ω."
        token.update_voices_manual(n)
        return f"‚úÖ {token.name}: –≥–æ–ª–æ—Å–∞ –≤—ã—Å—Ç–∞–≤–ª–µ–Ω—ã = {n}"

    def _format_races_simple(self, token) -> str:
        token._cleanup_expired_temp_races(force=True)
        parts: List[str] = []
        if token.races:
            parts.append("/".join(sorted(token.races)))

        temp_parts: List[str] = []
        for tr in token.temp_races:
            race_key = tr["race"]
            expires = tr["expires"]
            remaining = int(expires - time.time())
            if remaining > 0:
                if remaining >= 3600:
                    hours = remaining // 3600
                    minutes = (remaining % 3600) // 60
                    time_str = f"{hours}—á{minutes:02d}–º"
                else:
                    minutes = remaining // 60
                    seconds = remaining % 60
                    time_str = f"{minutes}–º{seconds:02d}—Å"
                temp_parts.append(f"{race_key}({time_str})")

        if temp_parts:
            parts.append("/".join(sorted(temp_parts)))

        return "/".join(parts) if parts else "-"

    def _format_apo_status(self) -> str:
        apostles = [t for t in self.tm.all_buffers() if t.class_type == "apostle"]
        warlocks = [t for t in self.tm.all_buffers() if t.class_type == "warlock"]
        paladins = [
            t
            for t in self.tm.all_buffers()
            if t.class_type in ("crusader", "light_incarnation")
        ]

        lines: List[str] = []

        if apostles:
            lines.append("üé≠ –ê–ø–æ—Å—Ç–æ–ª—ã")
            for t in apostles:
                races_str = self._format_races_simple(t)
                manual = " ‚ö†Ô∏è" if t.needs_manual_voices else ""
                lines.append(f" {t.name}: {races_str} | üó£Ô∏è {t.voices}{manual}")
            lines.append("")

        if warlocks:
            lines.append("üßô –ü—Ä–æ–∫–ª–∏–Ω–∞—é—â–∏–µ")
            for t in warlocks:
                manual = " ‚ö†Ô∏è" if t.needs_manual_voices else ""
                lines.append(f" {t.name} | üó£Ô∏è {t.voices}{manual}")
            lines.append("")

        if paladins:
            lines.append("‚öîÔ∏è –ü–∞–ª–∞–¥–∏–Ω—ã")
            for t in paladins:
                manual = " ‚ö†Ô∏è" if t.needs_manual_voices else ""
                lines.append(f" {t.name} (lvl {t.level}) | üó£Ô∏è {t.voices}{manual}")
            lines.append("")

        if not lines:
            return "–ù–µ—Ç –±–∞—Ñ–µ—Ä–æ–≤ –≤ –∫–æ–Ω—Ñ–∏–≥–µ."

        return "\n".join(lines).strip()

    def _handle_doprasa_command(
        self,
        from_id: int,
        text: str,
        msg_item: Dict[str, Any],
    ) -> None:
        parsed = parse_doprasa_cmd(text, msg_item)
        if not parsed:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                "‚ùå –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /–¥–æ–ø—Ä–∞—Å–∞ [—Ä–∞—Å–∞] [–∏–º—è_—Ç–æ–∫–µ–Ω–∞_–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ]\n"
                "üìå –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ä–∞—Å—ã, –µ—Å–ª–∏ –∞–ø–æ—Å—Ç–æ–ª –£–ñ–ï –ø–æ–ª—É—á–∏–ª –±–∞—Ñ –≤ –¥—Ä—É–≥–æ–º –º–µ—Å—Ç–µ\n"
                "üìå –ù—É–∂–Ω–æ –ø–µ—Ä–µ—Å–ª–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —É—Å–ø–µ—à–Ω—ã–º –±–∞—Ñ–æ–º\n"
                "–ü—Ä–∏–º–µ—Ä—ã:\n"
                " /–¥–æ–ø—Ä–∞—Å–∞ —á\n"
                " /–¥–æ–ø—Ä–∞—Å–∞ —á –ê–ø–æ—Å—Ç–æ–ª2",
                None,
            )
            return

        race_key, token_name, original_timestamp, _ = parsed

        token = None
        if token_name:
            token = self.tm.get_token_by_name(token_name)
            if not token:
                self.observer.send_to_peer(
                    self.observer.source_peer_id,
                    f"‚ùå –¢–æ–∫–µ–Ω '{token_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω.",
                    None,
                )
                return
            if token.owner_vk_id == 0:
                token.fetch_owner_id_lazy()
            if token.owner_vk_id != 0 and token.owner_vk_id != from_id:
                self.observer.send_to_peer(
                    self.observer.source_peer_id,
                    f"‚ùå –ù–µ—Ç –ø—Ä–∞–≤ –Ω–∞ '{token_name}'.",
                    None,
                )
                return
        else:
            token = self.tm.get_token_by_sender_id(from_id)
            if not token:
                self.observer.send_to_peer(
                    self.observer.source_peer_id,
                    f"‚ùå –ê–ø–æ—Å—Ç–æ–ª —Å –≤–∞—à–∏–º ID ({from_id}) –Ω–µ –Ω–∞–π–¥–µ–Ω.",
                    None,
                )
                return

        if token.id == self.observer.id:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                "‚ùå Observer —Ç–æ–∫–µ–Ω –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∞–ø–æ—Å—Ç–æ–ª–æ–º –∏ –Ω–µ –º–æ–∂–µ—Ç –ø–æ–ª—É—á–∞—Ç—å —Ä–∞—Å—ã.",
                None,
            )
            return

        if token.class_type != "apostle":
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                f"‚ùå {token.name} –Ω–µ –∞–ø–æ—Å—Ç–æ–ª.",
                None,
            )
            return

        token._cleanup_expired_temp_races(force=True)

        if race_key in token.races:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                f"‚ö†Ô∏è –£ {token.name} —É–∂–µ –µ—Å—Ç—å –ø–æ—Å—Ç–æ—è–Ω–Ω–∞—è —Ä–∞—Å–∞.",
                None,
            )
            return

        if any(tr["race"] == race_key for tr in token.temp_races):
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                f"‚ö†Ô∏è –£ {token.name} —É–∂–µ –µ—Å—Ç—å —ç—Ç–∞ –≤—Ä–µ–º–µ–Ω–Ω–∞—è —Ä–∞—Å–∞.",
                None,
            )
            return

        if token.get_temp_race_count() >= 1:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                f"‚ö†Ô∏è –£ {token.name} —É–∂–µ –µ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–∞—è —Ä–∞—Å–∞ (–º–æ–∂–Ω–æ —Ç–æ–ª—å–∫–æ –æ–¥–Ω—É).",
                None,
            )
            return

        if not original_timestamp:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                "‚ùå –ù—É–∂–Ω–æ –ø–µ—Ä–µ—Å–ª–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —É—Å–ø–µ—à–Ω—ã–º –±–∞—Ñ–æ–º.\n"
                "üìå –û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –±–∞—Ñ–æ–º –∏–ª–∏ –ø–µ—Ä–µ—à–ª–∏—Ç–µ –µ–≥–æ.",
                None,
            )
            return

        start_moscow = timestamp_to_moscow(original_timestamp)
        end_moscow = timestamp_to_moscow(original_timestamp + 2 * 3600)

        if end_moscow < now_moscow():
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                f"‚ùå –í—Ä–µ–º—è –±–∞—Ñ–∞ —É–∂–µ –∏—Å—Ç–µ–∫–ª–æ (—Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {format_moscow_time(start_moscow)}).",
                None,
            )
            return

        success = token.add_temporary_race(
            race_key, expires_at=original_timestamp + 2 * 3600
        )
        if success:
            self.tm.update_race_index(token)
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                f"‚úÖ {token.name}: –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–∞—è —Ä–∞—Å–∞ "
                f"'{RACE_NAMES.get(race_key, race_key)}'\n"
                f"‚è∞ {format_moscow_time(start_moscow)} ‚Üí {format_moscow_time(end_moscow)}\n"
                f"üìå –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å !–±–∞—Ñ{race_key}",
                None,
            )
        else:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ä–∞—Å—É –¥–ª—è {token.name}.",
                None,
            )

    # -------------------- Scheduler callback --------------------

    def _handle_buff_completion(self, job: Job, buff_info: Dict[str, Any]) -> None:
        should_finalize, snapshot = self.state.apply_completion(job, buff_info)
        if should_finalize and snapshot:
            txt = build_final_text(job.sender_id, snapshot, self.tm)
            if txt:
                sent_ok, send_status = self.observer.send_to_peer(
                    self.observer.source_peer_id, txt
                )
                if not sent_ok:
                    logging.error(
                        f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ {job.sender_id}: {send_status}"
                    )

    # -------------------- Message dispatch --------------------

    def _handle_new_message(self, msg_item: Dict[str, Any]) -> None:
        text = (msg_item.get("text") or "").strip()
        from_id = int(msg_item.get("from_id", 0))
        peer_id = int(msg_item.get("peer_id", 0))
        cmid = msg_item.get("conversation_message_id")

        if peer_id != self.observer.source_peer_id:
            return
        if from_id <= 0 or not text:
            return

        norm = normalize_text(text)

        if is_baf_cancel_cmd(norm):
            had_job, letters = self.state.cancel_and_clear(from_id)
            if not had_job:
                self.observer.send_to_peer(
                    self.observer.source_peer_id,
                    "‚ùå –£ –≤–∞—Å –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –±–∞—Ñ–æ–≤ –¥–ª—è –æ—Ç–º–µ–Ω—ã.",
                    None,
                )
                return
            cancelled = self.scheduler.cancel_user_jobs(from_id)
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                (
                    f"‚úÖ –í—Å–µ –≤–∞—à–∏ –±–∞—Ñ—ã ({letters}) –æ—Ç–º–µ–Ω–µ–Ω—ã."
                    if cancelled
                    else "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≤–∞—à–∏ –±–∞—Ñ—ã –≤ –æ—á–µ—Ä–µ–¥–∏."
                ),
                None,
            )
            return

        if norm in ["!–∑–¥–æ—Ä–æ–≤—å–µ", "!health", "!—Å—Ç–∞—Ç—É—Å"]:
            self._handle_health_command(from_id, text)
            return

        if norm.startswith("!–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞"):
            self._handle_diagnostic_command(from_id, text)
            return

        # ---- !–≥–æ–ª–æ—Å–∞ N: —Ç–æ–ª—å–∫–æ –ø–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—é ----
        parsed_g = parse_golosa_cmd(text)
        if parsed_g is not None:
            _, n = parsed_g

            token = self.tm.get_token_by_sender_id(from_id)
            if not token:
                self.observer.send_to_peer(
                    self.observer.source_peer_id,
                    f"‚ùå –î–ª—è –≤–∞—à–µ–≥–æ VK ID ({from_id}) –Ω–µ –Ω–∞–π–¥–µ–Ω —Ç–æ–∫–µ–Ω.",
                    None,
                )
                return

            reply = self._apply_manual_voices_by_name(token.name, n)
            self.observer.send_to_peer(self.observer.source_peer_id, reply, None)
            return

        if norm.startswith("/–¥–æ–ø—Ä–∞—Å–∞"):
            self._handle_doprasa_command(from_id, text, msg_item)
            return

        if is_apo_cmd(norm):
            status = self._format_apo_status()
            self.observer.send_to_peer(self.observer.source_peer_id, status, None)
            return

        letters = parse_baf_letters(text)
        if letters:
            if self.state.has_active(from_id):
                self.observer.send_to_peer(
                    self.observer.source_peer_id,
                    "‚ùå –£ –≤–∞—Å —É–∂–µ –µ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –±–∞—Ñ—ã. –î–æ–∂–¥–∏—Ç–µ—Å—å –∏—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–ª–∏ –æ—Ç–º–µ–Ω–∏—Ç–µ –∫–æ–º–∞–Ω–¥–æ–π '!–±–∞—Ñ –æ—Ç–º–µ–Ω–∞'.",
                    None,
                )
                return

            job = Job(
                sender_id=from_id,
                trigger_text=text,
                letters=letters,
                created_ts=time.time(),
            )
            self.state.register_job(from_id, job, letters, cmid)

            if cmid:
                sent_ok, send_status = self.observer.send_to_peer(
                    self.observer.source_peer_id,
                    build_registration_text(letters),
                )
                if sent_ok and "OK:" in (send_status or ""):
                    try:
                        mid = int(send_status.split(":")[1])
                        self.state.update_message_id(from_id, mid)
                    except Exception:
                        pass

            self.scheduler.enqueue_letters(job, letters)
