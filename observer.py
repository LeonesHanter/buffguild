# -*- coding: utf-8 -*-
import logging
import time
from typing import Any, Dict, List, Optional, Tuple

import aiohttp

from .constants import CLASS_ABILITIES, RACE_NAMES
from .models import Job
from .scheduler import Scheduler
from .health import TokenHealthMonitor
from .validators import InputValidator
from .utils import timestamp_to_moscow, now_moscow, format_moscow_time, normalize_text

logger = logging.getLogger(__name__)


class ObserverBot:
    def __init__(self, tm, executor):
        self.tm = tm
        self.executor = executor

        # ‚úÖ –°–æ–∑–¥–∞–µ–º Scheduler —Å –∫–æ–ª–±—ç–∫–æ–º –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
        self.scheduler = Scheduler(tm, executor, on_buff_complete=self._handle_buff_completion)

        self.health_monitor = TokenHealthMonitor(tm)

        self.observer = tm.get_observer()
        if not self.observer.access_token:
            raise RuntimeError("Observer token has empty access_token")
        if not self.observer.source_peer_id:
            raise RuntimeError("Observer source_chat_id is missing")

        self.poll_interval = float(tm.settings.get("poll_interval", 2.0))
        self.poll_count = int(tm.settings.get("poll_count", 20))

        # ‚úÖ –ù–û–í–û–ï: –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –±–∞—Ñ–æ–≤
        self._active_jobs: Dict[int, Dict] = {}  # user_id -> {job, letters, registration_info}
        self._buff_results: Dict[int, Dict] = {}  # user_id -> {tokens_info, total_value, expected_count, completed_count}

        logging.info("ü§ñ MultiTokenBot STARTED (Observer=LongPoll)")
        logging.info(f"üìã Tokens: {len(tm.tokens)}")
        logging.info(f"üõ∞Ô∏è Target poll: interval={self.poll_interval}s, count={self.poll_count}")

        self._lp_server: str = ""
        self._lp_key: str = ""
        self._lp_ts: str = ""

    def _parse_baf_letters(self, text: str) -> str:
        text_n = normalize_text(text)
        if not text_n.startswith("!–±–∞—Ñ"):
            return ""
        s = text_n[4:].strip()
        if not s:
            return ""
        s = s[:4]

        allowed = set()
        for cls in CLASS_ABILITIES.values():
            allowed.update(cls["abilities"].keys())
        out = "".join([ch for ch in s if ch in allowed])
        return out[:4]

    def _is_apo_cmd(self, text: str) -> bool:
        return normalize_text(text).startswith("!–∞–ø–æ")

    def _is_baf_cancel_cmd(self, text: str) -> bool:
        return normalize_text(text) == "!–±–∞—Ñ –æ—Ç–º–µ–Ω–∞"

    def _parse_golosa_cmd(self, text: str) -> Optional[Tuple[str, int]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–º–∞–Ω–¥—ã !–≥–æ–ª–æ—Å–∞"""
        t = (text or "").strip()
        if not normalize_text(t).startswith("!–≥–æ–ª–æ—Å–∞"):
            return None
        parts = t.split()
        if len(parts) != 3:
            return None
        name = parts[1].strip()
        try:
            n = int(parts[2].strip())
        except Exception:
            return None
        if not name:
            return None
        return name, max(0, n)

    def _apply_manual_voices_by_name(self, name: str, n: int) -> str:
        """–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ä—É—á–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤"""
        token = self.tm.get_token_by_name(name)
        if not token:
            return f"‚ùå –¢–æ–∫–µ–Ω —Å –∏–º–µ–Ω–µ–º '{name}' –Ω–µ –Ω–∞–π–¥–µ–Ω."
        token.update_voices_manual(n)
        # ‚úÖ –¢–µ–ø–µ—Ä—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±—É–¥–µ—Ç —á–µ—Ä–µ–∑ –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã–π –º–µ—Ö–∞–Ω–∏–∑–º
        return f"‚úÖ {token.name}: –≥–æ–ª–æ—Å–∞ –≤—ã—Å—Ç–∞–≤–ª–µ–Ω—ã = {n}"

    def _format_races_simple(self, token) -> str:
        # ‚úÖ force cleanup —á—Ç–æ–±—ã !–∞–ø–æ –ø–æ–∫–∞–∑—ã–≤–∞–ª–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
        token._cleanup_expired_temp_races(force=True)

        parts = []
        if token.races:
            parts.append("/".join(sorted(token.races)))

        temp_parts = []
        for tr in token.temp_races:
            race_key = tr["race"]
            expires = tr["expires"]
            remaining = int(expires - time.time())
            if remaining > 0:
                if remaining >= 3600:
                    hours = remaining // 3600
                    minutes = (remaining % 3600) // 60
                    time_str = f"{hours}—á{minutes:02d}–º"
                else:
                    minutes = remaining // 60
                    seconds = remaining % 60
                    time_str = f"{minutes}–º{seconds:02d}—Å"
                temp_parts.append(f"{race_key}({time_str})")

        if temp_parts:
            parts.append("/".join(sorted(temp_parts)))

        return "/".join(parts) if parts else "-"

    def _format_apo_status(self) -> str:
        apostles = [t for t in self.tm.all_buffers() if t.class_type == "apostle"]
        warlocks = [t for t in self.tm.all_buffers() if t.class_type == "warlock"]
        paladins = [t for t in self.tm.all_buffers() if t.class_type in ("crusader", "light_incarnation")]

        lines: List[str] = []

        if apostles:
            lines.append("üé≠ –ê–ø–æ—Å—Ç–æ–ª—ã")
            for t in apostles:
                races_str = self._format_races_simple(t)
                manual = " ‚ö†Ô∏è" if t.needs_manual_voices else ""
                lines.append(f"  {t.name}: {races_str} | üó£Ô∏è {t.voices}{manual}")
            lines.append("")

        if warlocks:
            lines.append("üßô –ü—Ä–æ–∫–ª–∏–Ω–∞—é—â–∏–µ")
            for t in warlocks:
                manual = " ‚ö†Ô∏è" if t.needs_manual_voices else ""
                lines.append(f"  {t.name} | üó£Ô∏è {t.voices}{manual}")
            lines.append("")

        if paladins:
            lines.append("‚öîÔ∏è –ü–∞–ª–∞–¥–∏–Ω—ã")
            for t in paladins:
                manual = " ‚ö†Ô∏è" if t.needs_manual_voices else ""
                lines.append(f"  {t.name} (lvl {t.level}) | üó£Ô∏è {t.voices}{manual}")
            lines.append("")

        if not lines:
            return "–ù–µ—Ç –±–∞—Ñ–µ—Ä–æ–≤ –≤ –∫–æ–Ω—Ñ–∏–≥–µ."
        return "\n".join(lines).strip()

    def _parse_doprasa_cmd(self, text: str, msg_item: Dict[str, Any]) -> Optional[Tuple[str, Optional[str], Optional[int], str]]:
        t = InputValidator.sanitize_text(text, max_length=50)
        if not normalize_text(t).startswith("/–¥–æ–ø—Ä–∞—Å–∞"):
            return None

        parts = t.split()
        if len(parts) < 2 or len(parts) > 3:
            return None

        race = parts[1].strip().lower()
        if not InputValidator.validate_race_key(race):
            return None

        token_name = None
        if len(parts) == 3:
            token_name = parts[2].strip()
            if not InputValidator.validate_token_name(token_name):
                return None

        original_timestamp = None
        if "reply_message" in msg_item:
            original_timestamp = InputValidator.validate_timestamp(msg_item["reply_message"].get("date"))
        elif "fwd_messages" in msg_item and msg_item["fwd_messages"]:
            original_timestamp = InputValidator.validate_timestamp(msg_item["fwd_messages"][0].get("date"))

        return race, token_name, original_timestamp, text

    def _handle_doprasa_command(self, from_id: int, text: str, msg_item: Dict[str, Any]) -> None:
        parsed = self._parse_doprasa_cmd(text, msg_item)
        if not parsed:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                "‚ùå –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /–¥–æ–ø—Ä–∞—Å–∞ [—Ä–∞—Å–∞] [–∏–º—è_—Ç–æ–∫–µ–Ω–∞_–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ]\n"
                "üìå –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ä–∞—Å—ã, –µ—Å–ª–∏ –∞–ø–æ—Å—Ç–æ–ª –£–ñ–ï –ø–æ–ª—É—á–∏–ª –±–∞—Ñ –≤ –¥—Ä—É–≥–æ–º –º–µ—Å—Ç–µ\n"
                "üìå –ù—É–∂–Ω–æ –ø–µ—Ä–µ—Å–ª–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —É—Å–ø–µ—à–Ω—ã–º –±–∞—Ñ–æ–º\n"
                "–ü—Ä–∏–º–µ—Ä—ã:\n"
                "  /–¥–æ–ø—Ä–∞—Å–∞ —á\n"
                "  /–¥–æ–ø—Ä–∞—Å–∞ —á –ê–ø–æ—Å—Ç–æ–ª2",
                None,
            )
            return

        race_key, token_name, original_timestamp, _ = parsed

        token = None
        if token_name:
            token = self.tm.get_token_by_name(token_name)
            if not token:
                self.observer.send_to_peer(self.observer.source_peer_id, f"‚ùå –¢–æ–∫–µ–Ω '{token_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω.", None)
                return

            if token.owner_vk_id == 0:
                token.fetch_owner_id_lazy()

            if token.owner_vk_id != 0 and token.owner_vk_id != from_id:
                self.observer.send_to_peer(self.observer.source_peer_id, f"‚ùå –ù–µ—Ç –ø—Ä–∞–≤ –Ω–∞ '{token_name}'.", None)
                return
        else:
            token = self.tm.get_token_by_sender_id(from_id)
            if not token:
                self.observer.send_to_peer(self.observer.source_peer_id, f"‚ùå –ê–ø–æ—Å—Ç–æ–ª —Å –≤–∞—à–∏–º ID ({from_id}) –Ω–µ –Ω–∞–π–¥–µ–Ω.", None)
                return

        # ‚úÖ –î–û–ë–ê–í–ò–¢–¨: –ø—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —ç—Ç–æ –Ω–µ Observer
        if token.id == self.observer.id:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                "‚ùå Observer —Ç–æ–∫–µ–Ω –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∞–ø–æ—Å—Ç–æ–ª–æ–º –∏ –Ω–µ –º–æ–∂–µ—Ç –ø–æ–ª—É—á–∞—Ç—å —Ä–∞—Å—ã.",
                None
            )
            return

        if token.class_type != "apostle":
            self.observer.send_to_peer(self.observer.source_peer_id, f"‚ùå {token.name} –Ω–µ –∞–ø–æ—Å—Ç–æ–ª.", None)
            return

        token._cleanup_expired_temp_races(force=True)

        if race_key in token.races:
            self.observer.send_to_peer(self.observer.source_peer_id, f"‚ö†Ô∏è –£ {token.name} —É–∂–µ –µ—Å—Ç—å –ø–æ—Å—Ç–æ—è–Ω–Ω–∞—è —Ä–∞—Å–∞.", None)
            return

        if any(tr["race"] == race_key for tr in token.temp_races):
            self.observer.send_to_peer(self.observer.source_peer_id, f"‚ö†Ô∏è –£ {token.name} —É–∂–µ –µ—Å—Ç—å —ç—Ç–∞ –≤—Ä–µ–º–µ–Ω–Ω–∞—è —Ä–∞—Å–∞.", None)
            return

        if token.get_temp_race_count() >= 1:
            self.observer.send_to_peer(self.observer.source_peer_id, f"‚ö†Ô∏è –£ {token.name} —É–∂–µ –µ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–∞—è —Ä–∞—Å–∞ (–º–æ–∂–Ω–æ —Ç–æ–ª—å–∫–æ –æ–¥–Ω—É).", None)
            return

        if not original_timestamp:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                "‚ùå –ù—É–∂–Ω–æ –ø–µ—Ä–µ—Å–ª–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —É—Å–ø–µ—à–Ω—ã–º –±–∞—Ñ–æ–º.\nüìå –û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –±–∞—Ñ–æ–º –∏–ª–∏ –ø–µ—Ä–µ—à–ª–∏—Ç–µ –µ–≥–æ.",
                None,
            )
            return

        start_moscow = timestamp_to_moscow(original_timestamp)
        end_moscow = timestamp_to_moscow(original_timestamp + 2 * 3600)
        if end_moscow < now_moscow():
            self.observer.send_to_peer(self.observer.source_peer_id, f"‚ùå –í—Ä–µ–º—è –±–∞—Ñ–∞ —É–∂–µ –∏—Å—Ç–µ–∫–ª–æ (—Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {format_moscow_time(start_moscow)}).", None)
            return

        success = token.add_temporary_race(race_key, expires_at=original_timestamp + 2 * 3600)
        if success:
            self.tm.update_race_index(token)
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                f"‚úÖ {token.name}: –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–∞—è —Ä–∞—Å–∞ '{RACE_NAMES.get(race_key, race_key)}'\n"
                f"‚è∞ {format_moscow_time(start_moscow)} ‚Üí {format_moscow_time(end_moscow)}\n"
                f"üìå –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å !–±–∞—Ñ{race_key}",
                None,
            )
        else:
            self.observer.send_to_peer(self.observer.source_peer_id, f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ä–∞—Å—É –¥–ª—è {token.name}.", None)

    def _handle_health_command(self, from_id: int, text: str) -> None:
        report = self.health_monitor.get_detailed_report()
        if len(report) > 4000:
            report = report[:4000] + "\n... (—Å–æ–æ–±—â–µ–Ω–∏–µ –æ–±—Ä–µ–∑–∞–Ω–æ)"
        self.observer.send_to_peer(self.observer.source_peer_id, report, None)

    def _handle_diagnostic_command(self, from_id: int, text: str) -> None:
        parts = text.split()
        if len(parts) == 1:
            self.observer.send_to_peer(self.observer.source_peer_id, "‚ùå –£–∫–∞–∂–∏—Ç–µ –∏–º—è —Ç–æ–∫–µ–Ω–∞: !–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ [–∏–º—è_—Ç–æ–∫–µ–Ω–∞]", None)
            return
        token_name = parts[1].strip()
        report = self.health_monitor.get_detailed_report(token_name)
        self.observer.send_to_peer(self.observer.source_peer_id, report, None)

    def _lp_get_server(self) -> bool:
        data = {"access_token": self.observer.access_token, "v": "5.131", "lp_version": 3}
        ret = self.observer._vk.call(self.observer._vk.post("messages.getLongPollServer", data))
        if "error" in ret:
            err = ret["error"]
            logging.error(f"‚ùå LongPollServer error {err.get('error_code')} {err.get('error_msg')}")
            return False
        resp = ret.get("response", {})
        self._lp_server = str(resp.get("server", "")).strip()
        self._lp_key = str(resp.get("key", "")).strip()
        self._lp_ts = str(resp.get("ts", "")).strip()
        if not self._lp_server or not self._lp_key or not self._lp_ts:
            logging.error("‚ùå LongPollServer: missing server/key/ts")
            return False
        logging.info(f"‚úÖ LongPoll initialized: server={self._lp_server}, ts={self._lp_ts}")
        return True

    def _lp_check(self) -> Optional[Dict[str, Any]]:
        server = "https://" + self._lp_server
        data = {"act": "a_check", "key": self._lp_key, "ts": self._lp_ts, "wait": 25, "mode": 2, "version": 3}
        try:
            return self.observer._vk.call(self.observer._vk.raw_post(server, data))
        except aiohttp.ClientError as e:
            logging.error(f"üì° –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ LongPoll: {e}")
            return None
        except Exception as e:
            logging.error(f"‚ùå LongPoll a_check exception: {e}", exc_info=True)
            return None

    def _send_registration_notification(self, from_id: int, letters: str, cmid: int) -> int:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –±–∞—Ñ–∞"""
        queue_size = self.scheduler.get_queue_size()

        notification_text = (
            f"‚úÖ –ë–∞—Ñ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω: {letters}\n"
            f"üìä –û–∂–∏–¥–∞–µ—Ç—Å—è –±–∞—Ñ–æ–≤: {len(letters)}\n"
            f"üìå –î–ª—è –æ—Ç–º–µ–Ω—ã –Ω–∞–ø–∏—à–∏—Ç–µ: !–±–∞—Ñ –æ—Ç–º–µ–Ω–∞"
        )

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        sent_ok, send_status = self.observer.send_to_peer(
            self.observer.source_peer_id,
            notification_text
        )

        if sent_ok and "OK:" in send_status:
            try:
                message_id = int(send_status.split(":")[1])
                return message_id
            except:
                pass

        return 0

    def _send_final_notification(self, user_id: int):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –±–∞—Ñ–µ –∫–æ–≥–¥–∞ –≤—Å–µ –±–∞—Ñ—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã"""
        if user_id not in self._buff_results:
            return

        user_data = self._buff_results[user_id]

        if not user_data.get("tokens_info"):
            return

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        tokens_text = []
        for token_info in user_data["tokens_info"]:
            token_text = f"{token_info['token_name']}({token_info['buff_value']}"
            if token_info['is_critical']:
                token_text += "üçÄ"
            token_text += ")"
            tokens_text.append(token_text)

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        notification_text = (
            f"üéâ –ë–∞—Ñ —É—Å–ø–µ—à–Ω–æ –≤—ã–¥–∞–Ω!\n"
            f"üìà –ù–∞—á–∏—Å–ª–µ–Ω–æ: {', '.join(tokens_text)}\n"
            f"üìâ –í—ã—á—Ç–µ–Ω–æ: ({user_data['total_value']}) –±–∞–ª–∞–Ω—Å–∞"
        )

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        self.observer.send_to_peer(
            self.observer.source_peer_id,
            notification_text
        )

        # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if user_id in self._buff_results:
            del self._buff_results[user_id]

        if user_id in self._active_jobs:
            del self._active_jobs[user_id]

    def _handle_buff_completion(self, job: Job, buff_info: Dict):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –±–∞—Ñ–∞ - –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ Scheduler"""
        if not job or not buff_info:
            return

        user_id = job.sender_id

        # –ï—Å–ª–∏ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ job, –∑–Ω–∞—á–∏—Ç —ç—Ç–æ —Å—Ç–∞—Ä—ã–π –±–∞—Ñ –∏–ª–∏ –æ—à–∏–±–∫–∞
        if user_id not in self._active_jobs:
            logging.warning(f"‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω –±–∞—Ñ –¥–ª—è –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
            return

        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±–∞—Ñ–µ
        buff_value = buff_info.get("buff_value", 0)
        is_critical = buff_info.get("is_critical", False)
        buff_name = buff_info.get("buff_name", "")
        token_name = buff_info.get("token_name", "")

        # ‚úÖ –£–õ–£–ß–®–ï–ù–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫—Ä–∏—Ç - –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –µ—Å–ª–∏ executor –æ—à–∏–±—Å—è
        original_buff_value = buff_value
        original_is_critical = is_critical

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç –±–∞—Ñ–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ 30%
        if buff_name and ("30%" in buff_name or "+30%" in buff_name):
            is_critical = True
            buff_value = 150  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å—Ç–∞–≤–∏–º 150 –¥–ª—è –∫—Ä–∏—Ç–∞
            logging.info(f"üéØ Observer: –ü–ï–†–ï–û–ü–†–ï–î–ï–õ–ï–ù–û –∫–∞–∫ –∫—Ä–∏—Ç –ø–æ –ø—Ä–æ—Ü–µ–Ω—Ç—É –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏: {buff_name}")
        elif buff_name and ("20%" in buff_name or "+20%" in buff_name):
            is_critical = False
            buff_value = 100  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å—Ç–∞–≤–∏–º 100 –¥–ª—è –æ–±—ã—á–Ω–æ–≥–æ
            logging.info(f"üìä Observer: –ü–ï–†–ï–û–ü–†–ï–î–ï–õ–ï–ù–û –∫–∞–∫ –æ–±—ã—á–Ω—ã–π –ø–æ –ø—Ä–æ—Ü–µ–Ω—Ç—É –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏: {buff_name}")

        # –õ–æ–≥–∏—Ä—É–µ–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏
        if original_buff_value != buff_value or original_is_critical != is_critical:
            logging.info(f"üîÑ Observer: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –±–∞—Ñ–∞ {token_name}: {original_buff_value}->{buff_value}, –∫—Ä–∏—Ç {original_is_critical}->{is_critical}")

        logging.info(f"üì• Observer: –ü–æ–ª—É—á–µ–Ω –±–∞—Ñ –æ—Ç {token_name}: –∑–Ω–∞—á–µ–Ω–∏–µ={buff_value}, –∫—Ä–∏—Ç={is_critical}, –Ω–∞–∑–≤–∞–Ω–∏–µ='{buff_name}'")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if user_id not in self._buff_results:
            self._buff_results[user_id] = {
                "tokens_info": [],
                "total_value": 0,
                "expected_count": len(self._active_jobs[user_id]["letters"]),
                "completed_count": 0
            }

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        self._buff_results[user_id]["tokens_info"].append({
            "token_name": token_name,
            "buff_value": buff_value,
            "is_critical": is_critical
        })
        self._buff_results[user_id]["total_value"] += buff_value
        self._buff_results[user_id]["completed_count"] += 1

        logging.info(f"üìä Observer: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id}: –≤—ã–ø–æ–ª–Ω–µ–Ω–æ {self._buff_results[user_id]['completed_count']}/{self._buff_results[user_id]['expected_count']} –±–∞—Ñ–æ–≤")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—Å–µ –ª–∏ –±–∞—Ñ—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã
        if self._buff_results[user_id]["completed_count"] >= self._buff_results[user_id]["expected_count"]:
            # –í—Å–µ –±–∞—Ñ—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
            self._send_final_notification(user_id)

    def _handle_baf_cancel_command(self, from_id: int, cmid: int) -> None:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã !–±–∞—Ñ –æ—Ç–º–µ–Ω–∞"""
        if from_id not in self._active_jobs:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                "‚ùå –£ –≤–∞—Å –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –±–∞—Ñ–æ–≤ –¥–ª—è –æ—Ç–º–µ–Ω—ã.",
                None
            )
            return

        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ job
        job_info = self._active_jobs[from_id]
        letters = job_info.get("letters", "")

        # –û—Ç–º–µ–Ω—è–µ–º –±–∞—Ñ—ã –≤ scheduler
        cancelled = self.scheduler.cancel_user_jobs(from_id)

        # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        if from_id in self._buff_results:
            del self._buff_results[from_id]

        if from_id in self._active_jobs:
            del self._active_jobs[from_id]

        if cancelled:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                f"‚úÖ –í—Å–µ –≤–∞—à–∏ –±–∞—Ñ—ã ({letters}) –æ—Ç–º–µ–Ω–µ–Ω—ã.",
                None
            )
        else:
            self.observer.send_to_peer(
                self.observer.source_peer_id,
                "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≤–∞—à–∏ –±–∞—Ñ—ã –≤ –æ—á–µ—Ä–µ–¥–∏.",
                None
            )

    def _handle_new_message(self, msg_item: Dict[str, Any]) -> None:
        text = (msg_item.get("text") or "").strip()
        from_id = int(msg_item.get("from_id", 0))
        peer_id = int(msg_item.get("peer_id", 0))
        cmid = msg_item.get("conversation_message_id")

        if peer_id != self.observer.source_peer_id:
            return
        if from_id <= 0 or not text:
            return

        # –ö–æ–º–∞–Ω–¥–∞ !–±–∞—Ñ –æ—Ç–º–µ–Ω–∞
        if self._is_baf_cancel_cmd(text):
            self._handle_baf_cancel_command(from_id, cmid)
            return

        # –ö–æ–º–∞–Ω–¥–∞ !–∑–¥–æ—Ä–æ–≤—å–µ
        if normalize_text(text) in ["!–∑–¥–æ—Ä–æ–≤—å–µ", "!health", "!—Å—Ç–∞—Ç—É—Å"]:
            self._handle_health_command(from_id, text)
            return

        # –ö–æ–º–∞–Ω–¥–∞ !–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
        if normalize_text(text).startswith("!–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞"):
            self._handle_diagnostic_command(from_id, text)
            return

        # –ö–æ–º–∞–Ω–¥–∞ !–≥–æ–ª–æ—Å–∞
        parsed = self._parse_golosa_cmd(text)
        if parsed is not None:
            name, n = parsed
            token = self.tm.get_token_by_name(name)
            if not token:
                self.observer.send_to_peer(
                    self.observer.source_peer_id,
                    f"‚ùå –¢–æ–∫–µ–Ω —Å –∏–º–µ–Ω–µ–º '{name}' –Ω–µ –Ω–∞–π–¥–µ–Ω.",
                    None
                )
                return

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω owner_vk_id)
            if token.owner_vk_id == 0:
                token.fetch_owner_id_lazy()

            if token.owner_vk_id != 0 and token.owner_vk_id != from_id:
                logging.warning(
                    f"‚ö†Ô∏è –ù–µ–∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ !–≥–æ–ª–æ—Å–∞ –æ—Ç {from_id} –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {token.name} (–≤–ª–∞–¥–µ–ª–µ—Ü={token.owner_vk_id})"
                )
                self.observer.send_to_peer(
                    self.observer.source_peer_id,
                    f"‚ùå –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –Ω–∞ —Ç–æ–∫–µ–Ω '{name}'.",
                    None
                )
                return

            reply = self._apply_manual_voices_by_name(name, n)
            self.observer.send_to_peer(self.observer.source_peer_id, reply, None)
            return

        # –ö–æ–º–∞–Ω–¥–∞ /–¥–æ–ø—Ä–∞—Å–∞
        if normalize_text(text).startswith("/–¥–æ–ø—Ä–∞—Å–∞"):
            self._handle_doprasa_command(from_id, text, msg_item)
            return

        # –ö–æ–º–∞–Ω–¥–∞ !–∞–ø–æ
        if self._is_apo_cmd(text):
            status = self._format_apo_status()
            self.observer.send_to_peer(self.observer.source_peer_id, status, None)
            return

        # –ö–æ–º–∞–Ω–¥–∞ !–±–∞—Ñ
        letters = self._parse_baf_letters(text)
        if letters:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ —É–∂–µ –∞–∫—Ç–∏–≤–Ω—ã—Ö –±–∞—Ñ–æ–≤ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            if from_id in self._active_jobs:
                self.observer.send_to_peer(
                    self.observer.source_peer_id,
                    "‚ùå –£ –≤–∞—Å —É–∂–µ –µ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –±–∞—Ñ—ã. –î–æ–∂–¥–∏—Ç–µ—Å—å –∏—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–ª–∏ –æ—Ç–º–µ–Ω–∏—Ç–µ –∫–æ–º–∞–Ω–¥–æ–π '!–±–∞—Ñ –æ—Ç–º–µ–Ω–∞'.",
                    None
                )
                return

            job = Job(sender_id=from_id, trigger_text=text, letters=letters, created_ts=time.time())
            logging.info(f"üéØ !–±–∞—Ñ from {from_id}: {letters} [observer={self.observer.name}]")

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
            if cmid:
                message_id = self._send_registration_notification(from_id, letters, cmid)
                if message_id > 0:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ job
                    self._active_jobs[from_id] = {
                        "job": job,
                        "letters": letters,
                        "cmid": cmid,
                        "message_id": message_id,
                        "registration_time": time.time()
                    }

                    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    self._buff_results[from_id] = {
                        "tokens_info": [],
                        "total_value": 0,
                        "expected_count": len(letters),
                        "completed_count": 0
                    }

            self.scheduler.enqueue_letters(job, letters)

    def run(self):
        retry_count = 0
        max_retries = 10
        retry_delay = 5

        while True:
            try:
                if not self._lp_get_server():
                    logging.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å LongPoll —Å–µ—Ä–≤–µ—Ä (–ø–æ–ø—ã—Ç–∫–∞ {retry_count + 1}/{max_retries})")
                    retry_count += 1
                    if retry_count >= max_retries:
                        logging.critical("üí• –ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø–æ–ª—É—á–µ–Ω–∏—è LongPoll —Å–µ—Ä–≤–µ—Ä–∞")
                        break

                    time.sleep(min(retry_delay * retry_count, 300))
                    continue

                retry_count = 0
                logging.info(f"‚úÖ LongPoll –≥–æ—Ç–æ–≤. –°–ª—É—à–∞—é —á–∞—Ç {self.observer.source_peer_id}")

                while True:
                    try:
                        lp = self._lp_check()
                        if not lp:
                            time.sleep(2)
                            continue

                        if "failed" in lp:
                            error_code = lp.get("failed")
                            logging.warning(f"‚ö†Ô∏è LongPoll failed with code: {error_code}")

                            if error_code == 1:  # –ò—Å—Ç–æ—Ä–∏—è —É—Å—Ç–∞—Ä–µ–ª–∞ –∏–ª–∏ –±—ã–ª–∞ —á–∞—Å—Ç–∏—á–Ω–æ —É—Ç–µ—Ä—è–Ω–∞
                                new_ts = lp.get("ts")
                                if new_ts:
                                    self._lp_ts = str(new_ts)
                                    logging.info(f"üîÑ LongPoll: –æ–±–Ω–æ–≤–ª–µ–Ω ts –Ω–∞ {new_ts}")
                                continue

                            elif error_code == 2:  # –ö–ª—é—á —É—Å—Ç–∞—Ä–µ–ª
                                logging.info("üîÑ LongPoll: –∫–ª—é—á —É—Å—Ç–∞—Ä–µ–ª, –æ–±–Ω–æ–≤–ª—è—é...")
                                if not self._lp_get_server():
                                    time.sleep(5)
                                continue

                            elif error_code == 3:  # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —É—Å—Ç–∞—Ä–µ–ª–∞
                                logging.info("üîÑ LongPoll: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —É—Å—Ç–∞—Ä–µ–ª–∞, –æ–±–Ω–æ–≤–ª—è—é...")
                                if not self._lp_get_server():
                                    time.sleep(5)
                                continue

                            elif error_code == 4:  # –ù–µ–≤–µ—Ä–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞
                                logging.error("‚ùå LongPoll: –Ω–µ–≤–µ—Ä–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
                                time.sleep(60)
                                continue

                            else:
                                logging.error(f"‚ùå LongPoll: –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ {error_code}")
                                time.sleep(5)
                                continue

                        new_ts = lp.get("ts")
                        if new_ts is not None:
                            self._lp_ts = str(new_ts)

                        updates = lp.get("updates", []) or []
                        if not updates:
                            continue

                        msg_ids: List[int] = []
                        for u in updates:
                            if not isinstance(u, list) or not u:
                                continue
                            if int(u[0]) != 4:
                                continue
                            try:
                                msg_id = int(u[1])
                                p_id = int(u[3])
                            except Exception:
                                continue
                            if p_id == self.observer.source_peer_id:
                                msg_ids.append(msg_id)

                        if not msg_ids:
                            continue

                        items = self.observer.get_by_id(msg_ids)
                        for it in items:
                            self._handle_new_message(it)

                    except aiohttp.ClientError as e:
                        logging.error(f"üì° –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ LongPoll: {e}")
                        time.sleep(5)
                        continue
                    except Exception as e:
                        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ LongPoll —Ü–∏–∫–ª–µ: {e}", exc_info=True)
                        time.sleep(5)
                        continue

            except Exception as e:
                logging.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ Observer: {e}", exc_info=True)
                retry_count += 1
                if retry_count >= max_retries:
                    logging.critical("üí• –ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è")
                    break

                delay = min(retry_delay * (2 ** retry_count), 300)  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                logging.info(f"üîÑ –ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ {delay} —Å–µ–∫—É–Ω–¥ (–ø–æ–ø—ã—Ç–∫–∞ {retry_count}/{max_retries})")
                time.sleep(delay
